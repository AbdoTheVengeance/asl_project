
"""
OPTIMIZED 3-Phase Training Module for ASL Recognition - TRAINING ONLY
"""
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import (
    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger
)
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import json
from datetime import datetime
import numpy as np

# âœ… Ø§Ø³ØªÙˆØ±Ø¯ Ù…Ù† config
from config import *
from model_builder import ModelBuilder
from utils import ensure_dir
from data_preprocessing import load_class_weights

# Set memory growth for GPU
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ… GPU Memory Growth Enabled: {len(gpus)} GPU(s) detected\n")
    except RuntimeError as e:
        print(e)


class OptimizedModelTrainer:
    """OPTIMIZED trainer with 3-phase training strategy"""

    def __init__(self, model_name):
        self.model_name = model_name
        self.model_builder = ModelBuilder(model_name)
        self.model = None
        self.history = None

        # Fix class weights loading
        weights_path = DATA_DIR / 'class_weights.json'
        if weights_path.exists():
            with open(weights_path, 'r') as f:
                class_weights_str = json.load(f)
            # Convert string keys to integers and ensure all values are Python floats
            self.class_weights = {}
            for key, value in class_weights_str.items():
                # Convert value to Python float if it's a tensor
                if hasattr(value, 'numpy'):
                    float_value = float(value.numpy())
                else:
                    float_value = float(value)
                self.class_weights[int(key)] = float_value
        else:
            self.class_weights = None

    def prepare_data_generators(self):
        """Prepare data generators using the external preprocessing module."""
        print("ğŸ“¦ Preparing CORRECTED Data Generators")

        # âœ…âœ… Ø§Ù„ØªØµØ­ÙŠØ­: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø¯Ø§Ù„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø§Øª Ù…Ù† Ù…Ù„Ù data_preprocessing.py
        from data_preprocessing import create_data_generators

        # ÙŠØ¬Ø¨ Ø£Ù† ØªÙ‚ÙˆÙ… Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ø¨Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
        train_generator, val_generator, test_generator = create_data_generators(self.model_name)

        # âœ… ØªØ£ÙƒØ¯ Ù…Ù† ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹
        self.steps_per_epoch_train = train_generator.samples // train_generator.batch_size
        self.steps_per_epoch_val = val_generator.samples // val_generator.batch_size

        return train_generator, val_generator, test_generator  # Ø§Ù„Ø¢Ù† test_generator Ù…ÙØ¹Ø±ÙÙ‘Ù

    def train_3_phase(self, train_gen, val_gen):
        """3-Phase OPTIMIZED Training Strategy"""
        print(f"\n{'=' * 60}")
        print(f"ğŸ¯ Starting 3-Phase Training: {self.model_name}")
        print(f"{'=' * 60}")

        # Phase 1: Feature Extraction
        print(f"\nğŸ“š PHASE 1: Feature Extraction (Frozen Base)")
        print(f"{'-' * 50}")

        # Build model (base frozen by default)
        self.model = self.model_builder.build_model()

        # âœ… Ø§Ø³ØªØ®Ø¯Ù… MAX_EPOCHS_PHASE1 Ù…Ù† config
        phase1_history = self.model.fit(
            train_gen,
            validation_data=val_gen,
            epochs=MAX_EPOCHS_PHASE1,
            callbacks=self.model_builder.get_callbacks(phase=1),
            verbose=1,
            class_weight=self.class_weights
        )

        # Phase 2: Fine-tuning top layers
        print(f"\nğŸ”§ PHASE 2: Fine-tuning Top Layers")
        print(f"{'-' * 50}")

        self.model_builder.unfreeze_for_finetuning(phase=2)

        # âœ… Ø§Ø³ØªØ®Ø¯Ù… MAX_EPOCHS_PHASE2 Ù…Ù† config
        phase2_history = self.model.fit(
            train_gen,
            validation_data=val_gen,
            epochs=MAX_EPOCHS_PHASE2,
            callbacks=self.model_builder.get_callbacks(phase=2),
            verbose=1,
            class_weight=self.class_weights
        )

        # # Phase 3: Full fine-tuning
        # print(f"\nğŸ¯ PHASE 3: Full Model Fine-tuning")
        # print(f"{'-' * 50}")
        #
        # self.model_builder.unfreeze_for_finetuning(phase=3)
        #
        # # âœ… Ø§Ø³ØªØ®Ø¯Ù… MAX_EPOCHS_PHASE3 Ù…Ù† config
        # phase3_history = self.model.fit(
        #     train_gen,
        #     validation_data=val_gen,
        #     epochs=MAX_EPOCHS_PHASE3,
        #     callbacks=self.model_builder.get_callbacks(phase=3),
        #     verbose=1,
        #     class_weight=self.class_weights
        # )

        # Combine histories
        self.history = self._combine_histories([phase1_history, phase2_history])#phase3_history

        print(f"\nâœ… 3-Phase Training Complete!")

        # ğŸ’¡ğŸ’¡ Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙˆØ§Ù„Ø£ÙƒØ«Ø± Ù‚ÙˆØ©: Ø­ÙØ¸ Ø§Ù„Ù‡ÙŠÙƒÙ„Ø© ÙˆØ§Ù„Ø£ÙˆØ²Ø§Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©
        
        # 1. Ø­ÙØ¸ Ù‡ÙŠÙƒÙ„Ø© Ø§Ù„Ù…ÙˆØ¯Ù„ (Architecture) Ø¥Ù„Ù‰ JSON
        try:
            model_json = self.model.to_json()
            arch_path = SAVED_MODELS_DIR / f'{self.model_name}_architecture.json'
            with open(arch_path, "w") as json_file:
                json_file.write(model_json)
            print(f"âœ… Model architecture saved to JSON: {arch_path}")
        except Exception as e:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®Ø·Ø£ ÙˆØ§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±
            print(f"âŒ WARNING: Failed to save model architecture to JSON due to {type(e).__name__}.")
            print("âš ï¸ Ø§Ù„Ø³Ø¨Ø¨: ÙƒØ§Ø¦Ù† TensorFlow Tensor Ø¹Ø§Ù„Ù‚ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ¯Ù„ (Ù…Ø«Ù„ L2 Regularization).")
            print("âš ï¸ Ø³ÙŠØ³ØªÙ…Ø± Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨Ø­ÙØ¸ Ø§Ù„Ø£ÙˆØ²Ø§Ù†ØŒ ÙˆÙŠÙ…ÙƒÙ† Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ModelBuilder + load_weights().")
            print(f"   Error details: {e}")
        
        # 2. Ø­ÙØ¸ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…ÙˆØ¯Ù„ (Weights Only) Ø¥Ù„Ù‰ H5 (Ù‡Ø°Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø¤ÙƒØ¯)
        try:
            weights_path = SAVED_MODELS_DIR / f'{self.model_name}_weights_only.h5'
            self.model.save_weights(weights_path)
            print(f"âœ… Final model weights saved to H5: {weights_path}")
        except Exception as e:
            print(f"âŒ CRITICAL ERROR: Failed to save model weights! {e}")

        print(f"{'=' * 60}\n")

        return self.history

    def _combine_histories(self, histories):
        """Combine multiple history objects"""
        combined_history = {}

        for key in histories[0].history.keys():
            combined_history[key] = []
            for history in histories:
                combined_history[key].extend(history.history[key])

        return type('History', (), {'history': combined_history})()

    # âŒ ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø¯Ø§Ù„Ø© evaluate_on_test
    # âŒ ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø¯Ø§Ù„Ø© evaluate_on_real_world

    def save_training_history(self):
        """Save training history to CSV - FIXED AGAINST KEY ERROR"""
        if self.history is None or not self.history.history: # Ø¥Ø¶Ø§ÙØ© ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ù„ÙŠØ³ ÙØ§Ø±ØºØ§Ù‹
            print("âš ï¸ No valid training history to save!")
            return

        ensure_dir(LOGS_DIR)
        
        history_data = self.history.history

        # ğŸ’¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…ÙØªØ§Ø­ 'loss' Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ø§Ù„Ù€ Epochs
        if 'loss' not in history_data:
            print("âŒ CRITICAL ERROR: 'loss' metric not found in combined history. Cannot save history.")
            print(f"   Available keys in history: {list(history_data.keys())}")
            return

        # Convert to DataFrame
        num_epochs = len(history_data['loss'])
        history_dict = {
            'epoch': list(range(1, num_epochs + 1)),
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… .get() Ù…Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† NaN Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø­Ø¯ÙˆØ« KeyError
            'loss': history_data['loss'],
            'accuracy': history_data.get('accuracy', [np.nan] * num_epochs),
            'precision': history_data.get('precision', [np.nan] * num_epochs),
            'recall': history_data.get('recall', [np.nan] * num_epochs),
            'val_loss': history_data.get('val_loss', [np.nan] * num_epochs),
            'val_accuracy': history_data.get('val_accuracy', [np.nan] * num_epochs),
            'val_precision': history_data.get('val_precision', [np.nan] * num_epochs),
            'val_recall': history_data.get('val_recall', [np.nan] * num_epochs),
        }

        # Add learning rate if available
        if 'lr' in history_data:
            history_dict['learning_rate'] = history_data['lr']

        df = pd.DataFrame(history_dict)

        # Save to CSV
        csv_path = LOGS_DIR / f'{self.model_name}_optimized_history.csv'
        df.to_csv(csv_path, index=False)
        print(f"âœ… Training history saved to CSV: {csv_path}")

        # Also save summary stats
        summary = {
            'model_name': self.model_name,
            'total_epochs': len(df),
            'best_val_accuracy': float(df['val_accuracy'].max()),
            'best_val_accuracy_epoch': int(df['val_accuracy'].idxmax() + 1),
            'final_val_accuracy': float(df['val_accuracy'].iloc[-1]),
            'final_train_accuracy': float(df['accuracy'].iloc[-1]),
            'best_val_loss': float(df['val_loss'].min()),
            'training_strategy': '3-Phase Optimized',
            'class_weights_used': bool(self.class_weights),
            'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

        summary_path = LOGS_DIR / f'{self.model_name}_optimized_summary.json'
        with open(summary_path, 'w') as f:
            json.dump(summary, f, indent=4)
        print(f"âœ… Training summary saved to: {summary_path}")

        return df

    def plot_training_history(self):
        """Plot training history with phase markers"""
        if self.history is None:
            print("âš ï¸ No training history to plot!")
            return

        ensure_dir(DOCS_DIR)

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        epochs = range(1, len(self.history.history['loss']) + 1)

        # âœ… Phase boundaries (Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙŠÙ… Ù…Ù† config)
        phase1_end = MAX_EPOCHS_PHASE1
        phase2_end = MAX_EPOCHS_PHASE1 + MAX_EPOCHS_PHASE2

        # Accuracy
        axes[0, 0].plot(epochs, self.history.history.get('accuracy', [np.nan]*len(epochs)),
                        'b-', label='Train', linewidth=2)
        axes[0, 0].plot(epochs, self.history.history.get('val_accuracy', [np.nan]*len(epochs)),
                        'r-', label='Validation', linewidth=2)
        axes[0, 0].axvline(x=phase1_end, color='g', linestyle='--', alpha=0.7, label='Phase 1 End')
        axes[0, 0].axvline(x=phase2_end, color='orange', linestyle='--', alpha=0.7, label='Phase 2 End')
        axes[0, 0].set_title(f'{self.model_name} - Accuracy (3-Phase Training)',
                             fontweight='bold', fontsize=12)
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        # Loss
        axes[0, 1].plot(epochs, self.history.history.get('loss', [np.nan]*len(epochs)),
                        'b-', label='Train', linewidth=2)
        axes[0, 1].plot(epochs, self.history.history.get('val_loss', [np.nan]*len(epochs)),
                        'r-', label='Validation', linewidth=2)
        axes[0, 1].axvline(x=phase1_end, color='g', linestyle='--', alpha=0.7, label='Phase 1 End')
        axes[0, 1].axvline(x=phase2_end, color='orange', linestyle='--', alpha=0.7, label='Phase 2 End')
        axes[0, 1].set_title(f'{self.model_name} - Loss (3-Phase Training)',
                             fontweight='bold', fontsize=12)
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Loss')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        # Precision
        axes[1, 0].plot(epochs, self.history.history.get('precision', [np.nan]*len(epochs)),
                        'b-', label='Train', linewidth=2)
        axes[1, 0].plot(epochs, self.history.history.get('val_precision', [np.nan]*len(epochs)),
                        'r-', label='Validation', linewidth=2)
        axes[1, 0].set_title(f'{self.model_name} - Precision',
                             fontweight='bold', fontsize=12)
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Precision')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # Recall
        axes[1, 1].plot(epochs, self.history.history.get('recall', [np.nan]*len(epochs)),
                        'b-', label='Train', linewidth=2)
        axes[1, 1].plot(epochs, self.history.history.get('val_recall', [np.nan]*len(epochs)),
                        'r-', label='Validation', linewidth=2)
        axes[1, 1].set_title(f'{self.model_name} - Recall',
                             fontweight='bold', fontsize=12)
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Recall')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()

        plot_path = DOCS_DIR / f'{self.model_name}_3phase_training_curves.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        print(f"âœ… 3-Phase training curves saved to: {plot_path}")
        plt.close()


def train_single_model_optimized(model_name):
    """Train a single model with OPTIMIZED 3-phase strategy (Training Only)"""
    print(f"\n{'ğŸš€' * 30}")
    print(f"Starting OPTIMIZED 3-Phase Training: {model_name}")
    print(f"{'ğŸš€' * 30}")

    trainer = OptimizedModelTrainer(model_name)

    # Prepare data (test_gen is still created but not used for evaluation here)
    train_gen, val_gen, test_gen = trainer.prepare_data_generators()

    # Train with 3-phase strategy
    trainer.train_3_phase(train_gen, val_gen)

    # Save history
    df_history = trainer.save_training_history()

    # Plot
    trainer.plot_training_history()

    print(f"\n{'âœ…' * 30}")
    print(f"{model_name} - 3-Phase Training Complete!")
    # Ù†Ø·Ø¨Ø¹ ÙÙ‚Ø· Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ (Validation) Ù„Ø£Ù†Ù‡Ø§ Ù…ØªÙˆÙØ±Ø© Ù…Ù† Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    if df_history is not None:
        print(f"Best Val Accuracy: {df_history['val_accuracy'].max():.4f}")
    
    print(f"{'âœ…' * 30}\n")

    return trainer, df_history


def choose_and_train_model():
    """Ø§Ø®ØªÙŠØ§Ø± ÙˆØªØ¯Ø±ÙŠØ¨ Ù…ÙˆØ¯Ù„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· (ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·)"""
    print("\n" + "ğŸ¤–" * 30)
    print("Ù†Ø¸Ø§Ù… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯Ù„ Ù„Ù„ØªØ¯Ø±ÙŠØ¨")
    print("ğŸ¤–" * 30)

    # Ø¹Ø±Ø¶ Ø§Ù„Ù…ÙˆØ¯Ù„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
    print("\nğŸ“‹ Ø§Ù„Ù…ÙˆØ¯Ù„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:")
    available_models = ["ResNet50", "EfficientNetB0", "InceptionV3"]
    for i, model_name in enumerate(available_models, 1):
        print(f"   {i}. {model_name}")

    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯Ù„
    while True:
        try:
            choice = input(f"\nğŸ”¢ Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ù…ÙˆØ¯Ù„ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ ØªØ¯Ø±ÙŠØ¨Ù‡ (1-{len(available_models)}): ").strip()
            if not choice:
                print("âš ï¸  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù…!")
                continue

            choice_num = int(choice)
            if 1 <= choice_num <= len(available_models):
                selected_model = available_models[choice_num - 1]
                break
            else:
                print(f"âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø±Ù‚Ù… Ø¨ÙŠÙ† 1 Ùˆ {len(available_models)}")
        except ValueError:
            print("âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­!")

    print(f"\nğŸ¯ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯Ù„: {selected_model}")
    print("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...\n")

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯Ù„ Ø§Ù„Ù…Ø®ØªØ§Ø±
    trainer, history_df = train_single_model_optimized(selected_model)

    return trainer, history_df


if __name__ == "__main__":
    print("\n" + "ğŸ“" * 30)
    print("ASL - OPTIMIZED 3-Phase Training Strategy (Training Only)")
    print("ğŸ“" * 30 + "\n")

    # Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    print("ğŸ”§ Ø·Ø±Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªØ§Ø­Ø©:")
    print("   1. ØªØ¯Ø±ÙŠØ¨ Ù…ÙˆØ¯Ù„ ÙˆØ§Ø­Ø¯ (Ù…Ø³ØªØ­Ø³Ù†)")
    print("   2. ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¯Ù„Ø§Øª")

    while True:
        choice = input("\nğŸ”¢ Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (1 Ø£Ùˆ 2): ").strip()
        if choice in ['1', '2']:
            break
        print("âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± 1 Ø£Ùˆ 2!")

    if choice == '1':
        # ØªØ¯Ø±ÙŠØ¨ Ù…ÙˆØ¯Ù„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·
        trainer, history_df = choose_and_train_model()
    else:
        # ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¯Ù„Ø§Øª
        print("\nğŸš€ Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¯Ù„Ø§Øª...")
        results = {}
        for model_name in ["ResNet50", "EfficientNetB0", "InceptionV3"]:
            trainer, history_df = train_single_model_optimized(model_name)
            results[model_name] = {
                'trainer': trainer,
                'history_df': history_df,
            }

        print("\nğŸ‰ ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¯Ù„Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")

        # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·
        print("\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø§Ø¹ØªÙ…Ø§Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ ÙÙ‚Ø·):")
        print("=" * 65)
        print(f"{'Model':<20} {'Best Val Accuracy':<25} {'Epochs':<10}")
        print("=" * 65)
        for model_name, result in results.items():
            df = result['history_df']
            # ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† df Ù„ÙŠØ³Øª None Ù‚Ø¨Ù„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if df is not None:
                print(f"{model_name:<20} {df['val_accuracy'].max():<25.4f} {len(df):<10}")
            else:
                 print(f"{model_name:<20} {'N/A':<25} {'N/A':<10}")
        print("=" * 65)

    print("\n" + "âœ…" * 20)
    print("ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
    print("âœ…" * 20)
